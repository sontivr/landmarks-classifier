{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3 (ipykernel)","language":"python"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{},"version_major":2,"version_minor":0}}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Convolutional Neural Networks\n\n## Project: Write an Algorithm for Landmark Classification\n\n### A simple app\n\nIn this notebook we build a very simple app that uses our exported model.\n\n> <img src=\"static_images/icons/noun-info-2558213.png\" alt=\"?\" style=\"width:25px\"/> Note how we are not importing anything from our source code (we do not use any module from the ``src`` directory). This is because the exported model, differently from the model weights, is a standalone serialization of our model and therefore it does not need anything else. You can ship that file to anybody, and as long as they can import ``torch``, they will be able to use your model. This is very important for releasing pytorch models to production.\n\n### Test your app\nGo to a search engine for images (like Google Images) and search for images of some of the landmarks, like the Eiffel Tower, the Golden Gate Bridge, Machu Picchu and so on. Save a few examples locally, then upload them to your app to see how your model behaves!\n\nThe app will show the top 5 classes that the model think are most relevant for the picture you have uploaded","metadata":{},"id":"4bd2c6d3"},{"cell_type":"code","source":"import torch\nimport torchvision\nimport ipywidgets\nimport traitlets\nimport notebook\nprint(torch.__version__)\nprint(torchvision.__version__)\nprint(ipywidgets.__version__)\nprint(traitlets.__version__)\nprint(notebook.__version__)","metadata":{"trusted":true,"tags":[]},"execution_count":1,"outputs":[{"name":"stdout","text":"1.11.0+cu102\n0.12.0+cu102\n8.1.3\n5.9.0\n6.5.7\n","output_type":"stream"}],"id":"e8dbb98e-6e2a-4b62-ad25-ceaed4ed6233"},{"cell_type":"code","source":"from ipywidgets import VBox, Button, FileUpload, Output, Label\nfrom PIL import Image\nfrom IPython.display import display\nimport io\nimport numpy as np\nimport torchvision\nimport torchvision.transforms as T\nimport torch\n\n# Decide which model you want to use among the ones exported\nlearn_inf = torch.jit.load(\"checkpoints/transfer_exported.pt\") # YOUR CODE HERE\n\ndef on_click_classify(change):\n\n    # Load image that has been uploaded\n    # fn = io.BytesIO(btn_upload.data[-1])\n    fn = io.BytesIO(btn_upload.value[-1].content)\n\n    img = Image.open(fn)\n    img.load()\n\n    # Let's clear the previous output (if any)\n    out_pl.clear_output()\n\n    # Display the image\n    with out_pl:\n\n        ratio = img.size[0] / img.size[1]\n        c = img.copy()\n        c.thumbnail([ratio * 200, 200])\n        display(c)\n\n    # Transform to tensor\n    timg = T.ToTensor()(img).unsqueeze_(0)\n\n    # Calling the model\n    softmax = learn_inf(timg).data.cpu().numpy().squeeze()\n    \n    # Get the indexes of the classes ordered by softmax\n    # (larger first)\n    idxs = np.argsort(softmax)[::-1]\n    \n    # Loop over the classes with the largest softmax\n    for i in range(5):\n        # Get softmax value\n        p = softmax[idxs[i]]\n    \n        # Get class name\n        landmark_name = learn_inf.class_names[idxs[i]]\n        \n        labels[i].value = f\"{landmark_name} (prob: {p:.2f})\"\n\n\n# Putting back btn_upload to a widget for next cell\nbtn_upload = FileUpload()\n\nbtn_run = Button(description=\"Classify\")\nbtn_run.on_click(on_click_classify)\n\nlabels = []\nfor _ in range(5):\n    labels.append(Label())\n\nout_pl = Output()\nout_pl.clear_output()\n\nwgs = [Label(\"Please upload a picture of a landmark\"), btn_upload, btn_run, out_pl]\nwgs.extend(labels)\n\nVBox(wgs)","metadata":{"trusted":true,"tags":[]},"execution_count":3,"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"VBox(children=(Label(value='Please upload a picture of a landmark'), FileUpload(value=(), description='Upload'â€¦","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a210ac2a80e94f59ab229018b05a2119"}},"metadata":{}}],"id":"4eaff0e3"},{"cell_type":"markdown","source":"## (optional) Standalone app or web app\n\nYou can run this notebook as a standalone app on your computer by following these steps:\n\n1. Download this notebook in a directory on your machine\n2. Download the model export (for example, ``checkpoints/transfer_exported.pt``) in a subdirectory called ``checkpoints`` within the directory where you save the app.ipynb notebook\n3. Install voila if you don't have it already (``pip install voila``)\n4. Run your app: ``voila app.ipynb --show_tracebacks=True``\n5. Customize your notebook to make your app prettier and rerun voila\n\nYou can also deploy this app as a website using Binder: https://voila.readthedocs.io/en/stable/deploy.html#deployment-on-binder","metadata":{},"id":"f636f335"},{"cell_type":"markdown","source":"# Create your submission archive\n\nNow that you are done with your project, please run the following cell. It will generate a file containing all the code you have written, as well as the notebooks. Please submit that file to complete your project","metadata":{},"id":"e09d9dfc"},{"cell_type":"code","source":"!python src/create_submit_pkg.py","metadata":{},"execution_count":null,"outputs":[],"id":"6e12dcfe"},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[],"id":"76ada3f8"}]}